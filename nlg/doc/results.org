#+title: 实验结果图
#+date: Mon Feb 27 09:41:12 2023
#+author: Zi Liang
#+email: liangzid@stu.xjtu.edu.cn
#+latex_class: elegantpaper
#+filetags: ::

* 提升效果-验证想法的章节
** vary epochs 

|---------+--------|
| items   | values |
|---------+--------|
| dataset |    e2e |
| dropout |    0.6 |
| lr      |   8e-5 |
|---------+--------|

eval on last 100 samples.

results:

|-----------+--------+---------|
|     epoch |   BLEU | rouge-L |
|-----------+--------+---------|
|         1 | 0.3424 |  0.3930 |
|         2 | 0.3797 |  0.4189 |
|         3 | 0.4194 |  0.3982 |
|         4 | 0.4146 |  0.4139 |
|         5 | 0.3650 |  0.4098 |
|   finally | 0.3650 |  0.4090 |
|   bestval | 0.0926 |  0.2583 |
|  trainmin | 0.4093 |  0.4190 |
| w.o. EmRs |        |         |
|-----------+--------+---------|

结论：存在明显的过拟合现象。但是总体效果并不佳.
应该测试：
1. dropout too large?
2. other things...

** 测试采样的测试集是否合理
using trainmin in chapter =vary epochs=

|------------------+--------+---------|
| key              |   BLEU | rouge-L |
|------------------+--------+---------|
| last 100         | 0.4093 |  0.4190 |
| first 100        | 0.4872 |  0.4843 |
| 500-600          | 0.4358 |  0.4386 |
| overall          | 0.4653 |  0.4452 |
|------------------+--------+---------|
| all-final(dr0.6) | 0.4531 |  0.4430 |
| all-vanilla      | 0.6381 |  0.4871 |
|------------------+--------+---------|

train model seems better than finally ckpt.

结论：应该使用全部的测试集进行效果调优。部分数据集的结果很不准。

** vary dropout Training

吸取了上次的结果，这次采用所有的测试集进行实验

|-------------+--------+---------+---------+-----------|
|     dropout |   BLEU | rouge-L | ep2BLEU | ep2rougeL |
|-------------+--------+---------+---------+-----------|
|         0.2 |        |         |         |           |
|         0.3 |        |         |         |           |
|         0.4 | 0.3734 |  0.4046 |  0.4800 |    0.4457 |
|         0.5 | 0.4297 |  0.4183 |  0.4351 |    0.4177 |
|         0.6 | 0.4531 |  0.4430 |       - |         - |
|         0.7 | 0.4560 |  0.4333 |  0.4126 |    0.4365 |
|         0.8 | 0.4441 |  0.4369 |  0.4395 |    0.4259 |
| all-vanilla | 0.6381 |  0.4871 |       - |         - |
|-------------+--------+---------+---------+-----------|

 +测试结果：dropout选择0.7左右较佳+

测试了epoch2的结果，发现结果没有这么简单。目前认为：
1. dropout较小的模型可以较快的地收敛，但是更容易过拟合。
2. 目前从效果上来看，反而是dropout为0.4的模型获得了最好的效果。真是神奇。但是为了训练的稳定性，（代码已经跑上了），所以主要还是采用dropout=0.7进行后续的noise测试


现在做dpr=0.4上的vary epoch实验

|------------+--------+--------|
| eposide    |   BLEU | rougeL |
|------------+--------+--------|
| ep0        | 0.3145 | 0.4144 |
| ep1        | 0.4027 | 0.4189 |
| ep2        | 0.4800 | 0.4457 | ? 后续将会衡量其可复现性
| ep3        |        |        |
| ep4        |        |        |
| finally    |        |        |
| valmin     |        |        |
| trainmodel |        |        |
|------------+--------+--------|


** The effectiveness of noise

dropout=0.7

|-----------------+--------+---------+---------+-----------|
| noise threshold |   BLEU | rouge-L | BLEUep2 | rougeLep2 |
|-----------------+--------+---------+---------+-----------|
|             0.1 |        |         |         |           |
|             0.2 | 0.4560 |  0.4333 |  0.4126 |    0.4365 |
|             0.3 |        |         |  0.4522 |    0.4440 |
|             0.4 |        |         |  0.4775 |    0.4461 |
|             0.5 |        |         |  0.4514 |    0.4455 |
|             0.6 | 0.4941 |  0.4450 |  0.4146 |    0.4229 |
|             0.7 | 0.5064 |  0.4618 |  0.5131 |    0.4639 |
|             0.8 | 0.4769 |  0.4563 |  0.4380 |    0.4481 |
|     all-vanilla | 0.6381 |  0.4871 |       - | -         |
|-----------------+--------+---------+---------+-----------|

结论：noise的范围取0.7会有较好的效果。下面是dpr=0.7,noise=0.7时随着epoch变动而产生的精度变化：

|------------+--------+--------|
| eposide    |   BLEU | rougeL |
|------------+--------+--------|
| ep0        | 0.3820 | 0.4274 |
| ep1        | 0.4243 | 0.4366 |
| ep2        | 0.5131 | 0.4639 |
| ep3        | 0.4864 | 0.4528 |
| ep4        | 0.5064 | 0.4615 |
| finally    | 0.5064 | 0.4618 |
| valmin     | 0.3974 | 0.4222 |
| trainmodel |   0.4274 | 0.4389 |
|------------+--------+--------|

结论：至少要训练3个epoch。对于0.7这种高noise没有观察到过拟合问题


** Vary other training losses.

+ CE: vanilla crossEntropy
+ cosEm: consine embedding
+ mseEm: MSE embedding
+ SCE: tempratured CE
+ MSEh: MSE of hidden states



Hyperparamerters:
+ dropout=?
+ noise=0.7?
+ 

|-------------+------+---------|
| loss type   | BLEU | rouge-L |
|-------------+------+---------|
| CE          |      |         |
| CE+cosEM    |      |         |
| CE+mseEM    |      |         |
| CE+SCE+?EM  |      |         |
| CE+MSEh+?EM |      |         |
|-------------+------+---------|


** 

* 总体结果表格

** E2E

|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| model   |   bleu | meteor |  chrf++ | nist_mt |   rou1 |   rou2 |   rouL | rouSum |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| vanGPT2 | 0.6381 | 0.6162 | 58.6091 |  5.9059 | 0.6791 | 0.4172 | 0.4871 | 0.4873 |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
|         |        |        |         |         |        |        |        |        |

** WEB_NLG

|---------+--------+--------+---------+---------+--------+--------+--------+------|
| model   |   bleu | meteor |  chrf++ | nist_mt |   rou1 |   rou2 |   rouL | rouS |
|---------+--------+--------+---------+---------+--------+--------+--------+------|
| vanGPT2 | 0.5262 | 0.6558 | 68.9543 |  6.1507 | 0.7294 | 0.4979 | 0.6393 |      |
|---------+--------+--------+---------+---------+--------+--------+--------+------|
|         |        |        |         |         |        |        |        |      |

** MultiWoz2.1 NLG

|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| model   |   bleu | meteor |  chrf++ | nist_mt |   rou1 |   rou2 |   rouL | rouSum |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| vanGPT2 | 0.6381 | 0.6162 | 58.6091 |  5.9059 | 0.6791 | 0.4172 | 0.4871 | 0.4873 |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
|         |        |        |         |         |        |        |        |        |

** Daily Dialog

|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| model   |   bleu | meteor |  chrf++ | nist_mt |   rou1 |   rou2 |   rouL | rouSum |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
| vanGPT2 | 0.6381 | 0.6162 | 58.6091 |  5.9059 | 0.6791 | 0.4172 | 0.4871 | 0.4873 |
|---------+--------+--------+---------+---------+--------+--------+--------+--------|
|         |        |        |         |         |        |        |        |        |

















